#!/usr/bin/env python
"""
Carga uno o más archivos de GH Archive en un Stream Redis llamado
'user_activity'. Cada línea del .json(.gz) se convierte en un registro
con los campos: user_id, event_time, event_type, payload (JSON string).

Uso:
    python load_gharchive.py archivo1.json.gz archivo2.json.gz ...
    # por defecto se conecta a localhost:6379
    # variables de entorno REDIS_HOST y REDIS_PORT pueden sobreescribir
"""
import os
import sys
import gzip
import json
import redis
from tqdm import tqdm

# ------- Configuración de conexión ---------------------------------
HOST = os.getenv("REDIS_HOST", "localhost")
PORT = int(os.getenv("REDIS_PORT", 6379))
STREAM = "user_activity"
BATCH  = 10_000            # enviar cada 10 000 eventos

r = redis.Redis(host=HOST, port=PORT)

def ingest(path: str):
    opener = gzip.open if path.endswith(".gz") else open
    with opener(path, "rt", encoding="utf-8") as fh:
        pipe = r.pipeline()
        for i, line in enumerate(tqdm(fh, desc=os.path.basename(path))):
            ev = json.loads(line)
            record = {
                "user_id":   str(ev["actor"]["id"]),
                "event_time": ev["created_at"],        # 2025-04-01T12:34:56Z
                "event_type": ev["type"],              # PushEvent, IssuesEvent…
                "payload":   json.dumps(ev.get("payload") or {})
            }
            pipe.xadd(STREAM, record)
            if (i + 1) % BATCH == 0:
                pipe.execute()
        pipe.execute()  # últimos pendientes

if __name__ == "__main__":
    if len(sys.argv) < 2:
        sys.exit("Indica al menos un archivo .json o .json.gz de GH Archive")
    for file in sys.argv[1:]:
        ingest(file)
    print("✔ Ingesta terminada.")
